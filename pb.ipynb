{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Before exploring the notebook, change the colab runtime from normal cpu to gpu."
      ],
      "metadata": {
        "id": "yE5MF4CRBMDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing necessary packages"
      ],
      "metadata": {
        "id": "oQeb4YaLWgT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install byaldi streamlit pyngrok\n",
        "!sudo apt-get install -y poppler-utils\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "XNfiAPrnBGoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the data source from local to colab\n",
        "<img width=\"1470\" alt=\"Screenshot 2024-12-28 at 4 59 23‚ÄØPM\" src=\"https://github.com/user-attachments/assets/e3be932b-fbda-49ba-81a7-f7904e4b4200\" />\n",
        "<img width=\"1470\" alt=\"Screenshot 2024-12-28 at 5 01 09‚ÄØPM\" src=\"https://github.com/user-attachments/assets/5d5b6244-236a-4807-af9b-bcba0debc568\" />\n",
        "<img width=\"1470\" alt=\"Screenshot 2024-12-28 at 5 02 44‚ÄØPM\" src=\"https://github.com/user-attachments/assets/8337d446-7dd9-4928-8631-6800b9dcaf3a\" />\n",
        "<img width=\"1470\" alt=\"Screenshot 2024-12-28 at 5 03 22‚ÄØPM\" src=\"https://github.com/user-attachments/assets/6357adae-8de4-45bc-a93b-86e22ccc63cd\" />\n"
      ],
      "metadata": {
        "id": "DBxVWcc6Intx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the model for building the index\n"
      ],
      "metadata": {
        "id": "GdZ88DrfJuTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from byaldi import RAGMultiModalModel\n",
        "RAG = RAGMultiModalModel.from_pretrained(\"vidore/colpali-v1.2\")"
      ],
      "metadata": {
        "id": "HbBe5UioJl77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAG.index(\n",
        "    input_path=\"xxxxxxxxx\", # The path to your uploaded document\n",
        "    index_name=\"xxxxxxxxx\", # The name you want to give to your index. It'll be saved at `index_root/index_name/`.\n",
        "    store_collection_with_index=True, # Whether the index should store the base64 encoded documents.\n",
        "    overwrite=True # Whether to overwrite an index if it already exists. If False, it'll return None and do nothing if `index_root/index_name` exists.\n",
        ")"
      ],
      "metadata": {
        "id": "a6FgRKUqJ1ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It will save the index file under the folder name which you mentioned. Now the save the index to your google drive with the following command"
      ],
      "metadata": {
        "id": "-dwXO-xSKJJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/internship /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "fGmzDSpSJ9Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the basic RAG model in [Stack AI](https://www.stack-ai.com/) by following the images as follows:-\n",
        "<img width=\"1470\" alt=\"Screenshot 2024-12-28 at 5 51 42‚ÄØPM\" src=\"https://github.com/user-attachments/assets/46ac535f-bc22-4cc9-b8cf-818c9aecf15b\" />\n",
        "\n",
        "Follow the [Youtube](https://youtu.be/ZeZM_Zm7pgc) for better understanding of the deployment. Once save and publish, navigate to the export tab and copy the credentials under python code section as follows:-\n",
        "\n",
        "<img width=\"1470\" alt=\"Screenshot 2024-12-28 at 5 57 58‚ÄØPM\" src=\"https://github.com/user-attachments/assets/fc74673b-e30b-47c8-8e6a-d91a03f426f8\" />\n"
      ],
      "metadata": {
        "id": "QXTEIR8hNZm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the necessary packages"
      ],
      "metadata": {
        "id": "bLDGnA1dPdIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from byaldi import RAGMultiModalModel\n",
        "import logging\n",
        "import torch\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import re"
      ],
      "metadata": {
        "id": "uQ_DNdFKPfht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = \"xxxxxxxxxxxxx\"\n",
        "headers = {'Authorization':\n",
        "\t\t\t 'Bearer xxxxxxxxxx',\n",
        "\t\t\t 'Content-Type': 'application/json'\n",
        "\t\t}"
      ],
      "metadata": {
        "id": "uUApmAGcPhrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup account in [Gemini Cloud](https://ai.google.dev/) and copy paste the api key"
      ],
      "metadata": {
        "id": "o7YVsVsiPzM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Initialize Gemini\n",
        "api_key = \"xxxxxxxxxxxxxxx\"\n",
        "genai.configure(api_key=api_key)\n",
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest')\n",
        "\n",
        "\n",
        "# Load RAG model - Only load once at startup\n",
        "rag_model = RAGMultiModalModel.from_index(\"paste your index stored path\")"
      ],
      "metadata": {
        "id": "aIUhtKcTPV9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_CONTEXT = \"\"\"Please consider the provided image and the user's question for generating the final answer.\n",
        "If you are unable to understand or answer based on the images, please respond with 'I apologize, I cannot determine the answer from these images.'\"\"\""
      ],
      "metadata": {
        "id": "IzF9usGtQHS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now create a new file `app.py` in contents with the following code and save the file.\n",
        "<img width=\"1470\" alt=\"Screenshot 2024-12-28 at 6 03 10‚ÄØPM\" src=\"https://github.com/user-attachments/assets/5ae6369c-7f54-4b53-a2c5-5b435fffbb5c\" />\n"
      ],
      "metadata": {
        "id": "Bo4IDdCiQMjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "import streamlit as st\n",
        "import google.generativeai as genai\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from byaldi import RAGMultiModalModel\n",
        "import time\n",
        "import logging\n",
        "import json\n",
        "from datetime import datetime\n",
        "import requests\n",
        "import re\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('chatbot.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configure page title\n",
        "st.set_page_config(page_title=\"RAG Image Chatbot\", layout=\"wide\")\n",
        "st.title(\"Dual RAG Chatbot System\")\n",
        "\n",
        "# Initialize Gemini and other configurations\n",
        "api_key = \"gemini api key\"\n",
        "genai.configure(api_key=api_key)\n",
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest')\n",
        "\n",
        "# Stack AI API Configuration\n",
        "API_URL = \"xxxxxxxxxxxxxxx\"\n",
        "headers = {\n",
        "    'Authorization': 'Bearer xxxxxxxxxxxxxxxx',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "def query(payload):\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    return response.json()\n",
        "\n",
        "# Initialize RAG model\n",
        "@st.cache_resource\n",
        "def load_rag_model():\n",
        "    logger.info(\"Initializing RAG model\")\n",
        "    return RAGMultiModalModel.from_index(\"path to your index\")\n",
        "\n",
        "def clean_traditional_response(response):\n",
        "    \"\"\"Remove citations and clean up traditional RAG response\"\"\"\n",
        "    # Remove citations section and references\n",
        "    response = re.split(r'<citations>|Citations:', response)[0].strip()\n",
        "    response = re.sub(r'\\[\\^[\\d\\.]+\\]', '', response)\n",
        "    return response\n",
        "\n",
        "\n",
        "existing_index = load_rag_model()\n",
        "\n",
        "# Initialize session states\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "if \"show_logs\" not in st.session_state:\n",
        "    st.session_state.show_logs = False\n",
        "\n",
        "# System context for Gemini\n",
        "SYSTEM_CONTEXT = \"\"\"Please consider the provided image and the user's question for generating the final answer.\n",
        "If you are unable to understand or answer based on the images, please respond with 'I apologize, I cannot determine the answer from these images.'\"\"\"\n",
        "\n",
        "def base64_to_pil(base64_string):\n",
        "    if 'base64,' in base64_string:\n",
        "        base64_string = base64_string.split('base64,')[1]\n",
        "    img_bytes = base64.b64decode(base64_string)\n",
        "    img = Image.open(BytesIO(img_bytes))\n",
        "    return img\n",
        "\n",
        "# Sidebar\n",
        "with st.sidebar:\n",
        "    st.markdown(\"### About\")\n",
        "    st.markdown(\"This chatbot combines two RAG systems:\")\n",
        "    st.markdown(\"1. Multi-modal RAG (Left)\")\n",
        "    st.markdown(\"2. Text-based RAG (Right)\")\n",
        "\n",
        "    if st.button(\"Clear Chat History\"):\n",
        "        st.session_state.messages = []\n",
        "        st.rerun()\n",
        "\n",
        "    st.session_state.show_logs = st.checkbox(\"Show Processing Logs\",\n",
        "                                           value=st.session_state.show_logs)\n",
        "\n",
        "# Display chat history\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                st.markdown(\"### Multi-modal RAG\")\n",
        "                st.markdown(message.get(\"image_response\", \"\"))\n",
        "                if \"similarity_score\" in message:\n",
        "                    st.markdown(f\"**Similarity Score:** {message['similarity_score']:.2%}\")\n",
        "                if \"image\" in message:\n",
        "                    st.image(base64_to_pil(message[\"image\"]),\n",
        "                            caption=\"Retrieved Image\",\n",
        "                            use_column_width=True)\n",
        "            with col2:\n",
        "                st.markdown(\"### Text-based RAG\")\n",
        "                st.markdown(message.get(\"text_response\", \"\"))\n",
        "        else:\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "# Chat interface\n",
        "if prompt := st.chat_input(\"Ask your question here...\"):\n",
        "    logger.info(f\"Received query: {prompt}\")\n",
        "\n",
        "    # Add user message\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    # Process query in two columns\n",
        "    col1, col2 = st.columns(2)\n",
        "    text_response = \"\"\n",
        "    image_response = \"\"\n",
        "    image_base64 = None\n",
        "    similarity_score = None\n",
        "\n",
        "    # First column - Multi-modal RAG\n",
        "    with col1:\n",
        "        st.markdown(\"### Multi-modal RAG\")\n",
        "        with st.status(\"Processing multi-modal query...\") as status:\n",
        "            try:\n",
        "                st.write(\"üîç Searching relevant documents...\")\n",
        "                results = existing_index.search(prompt, k=1, return_base64_results=True)\n",
        "                similarity_score = results[0]['score']\n",
        "\n",
        "                st.write(\"üí≠ Generating response...\")\n",
        "                image_base64 = results[0]['base64']\n",
        "                pil_image = base64_to_pil(image_base64)\n",
        "\n",
        "                query_text = f\"{SYSTEM_CONTEXT}\\n\\nUser Question: {prompt}\"\n",
        "                response = model.generate_content([query_text, pil_image])\n",
        "                image_response = response.text\n",
        "\n",
        "                status.update(label=\"‚úÖ Multi-modal processing complete!\", state=\"complete\")\n",
        "\n",
        "                st.markdown(image_response)\n",
        "                st.markdown(f\"**Similarity Score:** {similarity_score:.2f}\")\n",
        "                st.image(pil_image, caption=\"Retrieved Image\", use_column_width=True)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Multi-modal RAG error: {str(e)}\")\n",
        "                st.error(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "    # Second column - Text-based RAG\n",
        "    with col2:\n",
        "        st.markdown(\"### Text-based RAG\")\n",
        "        with st.status(\"Processing text query...\") as status:\n",
        "            try:\n",
        "                st.write(\"üîç Processing query...\")\n",
        "                result = query({\n",
        "                    \"in-0\": prompt,\n",
        "                    \"user_id\": \"<USER or Conversation ID>\"\n",
        "                })\n",
        "                text_response = clean_traditional_response(result['outputs']['out-0'])\n",
        "                status.update(label=\"‚úÖ Text processing complete!\", state=\"complete\")\n",
        "                st.markdown(text_response)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Text RAG error: {str(e)}\")\n",
        "                st.error(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "    # Store assistant response in chat history\n",
        "    if text_response or image_response:\n",
        "        st.session_state.messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"text_response\": text_response,\n",
        "            \"image_response\": image_response,\n",
        "            \"image\": image_base64,\n",
        "            \"similarity_score\": similarity_score,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "# Display logs if enabled\n",
        "if st.session_state.show_logs:\n",
        "    st.divider()\n",
        "    st.markdown(\"### Processing Logs\")\n",
        "    try:\n",
        "        with open('chatbot.log', 'r') as log_file:\n",
        "            logs = log_file.readlines()[-10:]\n",
        "            for log in logs:\n",
        "                st.text(log.strip())\n",
        "    except FileNotFoundError:\n",
        "        st.info(\"No logs available yet. Start chatting to generate logs!\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading logs: {str(e)}\")\n",
        "\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "60hmob7rQ9iN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its time to start web application. For doing that login to the ngrok and create a authentication key"
      ],
      "metadata": {
        "id": "ywFxN2-RRJXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and set auth token\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "ngrok.set_auth_token(\"your ngrok auth token\")\n",
        "\n",
        "def launch_streamlit_with_ngrok():\n",
        "    # Kill any existing processes\n",
        "    !pkill -9 streamlit\n",
        "\n",
        "    # Start Streamlit\n",
        "    print(\"üöÄ Starting Streamlit...\")\n",
        "    !streamlit run /content/app.py &>/content/logs.txt &\n",
        "    time.sleep(3)  # Give Streamlit time to start\n",
        "\n",
        "    # Configure and start ngrok tunnel\n",
        "    print(\"üåê Creating secure tunnel...\")\n",
        "    # Close any existing tunnels\n",
        "    ngrok.kill()\n",
        "\n",
        "    # Create tunnel with explicit configuration\n",
        "    tunnel = ngrok.connect(\n",
        "        addr=8501,\n",
        "        proto=\"http\",  # Explicitly set protocol\n",
        "        bind_tls=True  # Enable HTTPS\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚ú® Your Streamlit app is live at:\", tunnel.public_url)\n",
        "    print(\"NOTE: The URL will be active as long as this Colab notebook is running\")\n",
        "    return tunnel.public_url\n",
        "\n",
        "# Launch everything\n",
        "try:\n",
        "    url = launch_streamlit_with_ngrok()\n",
        "except Exception as e:\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    # Try alternative configuration if first attempt fails\n",
        "    try:\n",
        "        url = ngrok.connect(8501)\n",
        "        print(\"\\n‚ú® Your Streamlit app is live at:\", url)\n",
        "    except Exception as e:\n",
        "        print(f\"Final Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "d017yHYzRp05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you run the above cell you may see as follows:-\n",
        "<img width=\"1470\" alt=\"Screenshot 2024-12-28 at 6 10 50‚ÄØPM\" src=\"https://github.com/user-attachments/assets/36507d48-2e2d-43a4-b0ca-3e7f20b32045\" />\n",
        "\n",
        "Then click on the first link , then it opens a new tab as follows:-\n",
        "<img width=\"1470\" alt=\"Screenshot 2024-12-28 at 6 26 58‚ÄØPM\" src=\"https://github.com/user-attachments/assets/af585cf8-13e2-4d95-841e-0902f665c913\" />\n"
      ],
      "metadata": {
        "id": "H7xsp-H3SDiO"
      }
    }
  ]
}